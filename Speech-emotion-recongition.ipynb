{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Emotion Recognition with Python\n",
    "\n",
    "The objective of this project is to build an automated emotion recognition for audio and speech files. This project is usable for: \n",
    "1. customer care call centres to effectively analyse their calls, record the emotion that each call has so customers' level of satisfaction can be predicted based on the emotions from the calls.\n",
    "2. customer order calls to identify if orders are urgent or not urgent based on the emotion that their voices carry\n",
    "3. Policemen to automatically differentiate between fake callers and callers who are genuine and are in need of urgent help.\n",
    "\n",
    "In this project, we will use the libraries librosa, soundfile, and sklearn (among others) to build a model using an MLPClassifier. This will be able to recognize emotion from sound files. We will load the data, extract features from it, then split the dataset into training and testing sets. Then, we’ll initialize an MLPClassifier and train the model. Finally, we’ll calculate the accuracy of our model.\n",
    "\n",
    "### The Dataset\n",
    "For this Python mini project, we’ll use the RAVDESS dataset; this is the Ryerson Audio-Visual Database of Emotional Speech and Song dataset. This dataset has 7356 files rated by 247 individuals 10 times on emotional validity, intensity, and genuineness. The entire dataset is 24.8GB from 24 actors, but we’ve lowered the sample rate on all the files,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in c:\\programdata\\anaconda3.1\\lib\\site-packages (0.8.0)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.11.tar.gz (37 kB)\n",
      "Requirement already satisfied: soundfile in c:\\programdata\\anaconda3.1\\lib\\site-packages (0.10.3.post1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (1.18.5)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (0.16.0)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (0.23.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from librosa) (0.50.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from soundfile) (1.14.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: six>=1.3 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3.1\\lib\\site-packages (from pooch>=1.0->librosa) (20.4)\n",
      "Requirement already satisfied: appdirs in c:\\programdata\\anaconda3.1\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3.1\\lib\\site-packages (from pooch>=1.0->librosa) (2.24.0)\n",
      "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from numba>=0.43.0->librosa) (0.33.0+1.g022ab0f)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3.1\\lib\\site-packages (from numba>=0.43.0->librosa) (49.2.0.post20200714)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3.1\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from requests->pooch>=1.0->librosa) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3.1\\lib\\site-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
      "Building wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (setup.py): started\n",
      "  Building wheel for pyaudio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyaudio\n",
      "Failed to build pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "    Running setup.py install for pyaudio: started"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3.1\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\oadepoju003\\AppData\\Local\\Temp\\pip-wheel-vkd26nco'\n",
      "       cwd: C:\\Users\\oadepoju003\\AppData\\Local\\Temp\\pip-install-cwp6hocw\\pyaudio\\\n",
      "  Complete output (9 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.8\n",
      "  copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "  running build_ext\n",
      "  building '_portaudio' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyaudio\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\ProgramData\\Anaconda3.1\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\oadepoju003\\AppData\\Local\\Temp\\pip-record-pj0hc1er\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3.1\\Include\\pyaudio'\n",
      "         cwd: C:\\Users\\oadepoju003\\AppData\\Local\\Temp\\pip-install-cwp6hocw\\pyaudio\\\n",
      "    Complete output (9 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.8\n",
      "    copying src\\pyaudio.py -> build\\lib.win-amd64-3.8\n",
      "    running build_ext\n",
      "    building '_portaudio' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Build Tools for Visual Studio\": https://visualstudio.microsoft.com/downloads/\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\ProgramData\\Anaconda3.1\\python.exe' -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\oadepoju003\\\\AppData\\\\Local\\\\Temp\\\\pip-install-cwp6hocw\\\\pyaudio\\\\setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\oadepoju003\\AppData\\Local\\Temp\\pip-record-pj0hc1er\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\ProgramData\\Anaconda3.1\\Include\\pyaudio' Check the logs for full command output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Running setup.py install for pyaudio: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa pyaudio soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract features (mfcc, chroma, mel) from a sound file\n",
    "def extract_feature(file_name, mfcc, chroma, mel):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        X = sound_file.read(dtype=\"float32\")\n",
    "        sample_rate=sound_file.samplerate\n",
    "        if chroma:\n",
    "            stft=np.abs(librosa.stft(X))\n",
    "        result=np.array([])\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            result=np.hstack((result, mfccs))\n",
    "        if chroma:\n",
    "            chroma=np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, chroma))\n",
    "        if mel:\n",
    "            mel=np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "            result=np.hstack((result, mel))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Extract as many features as possible with Librosa. As you extract more, more information is useful to build a stronger database\n",
    "2) Get tutorials on how to extract features with librosa\n",
    "3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creat a dictionary to get Emotions in the RAVDESS dataset\n",
    "emotions={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}\n",
    "\n",
    "#Create a list of Emotions to observe\n",
    "observed_emotions=['calm', 'happy', 'fearful', 'disgust']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The emotion is decoded in the file name. The file name is in elements separated by a '-'. The third element in the file name is the decoder for the emotions. In the next code, we will subset the file name and separate the emotion decoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test_size=0.2):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"C:\\\\Users\\\\oadepoju003\\\\Desktop\\\\Data science projects\\\\SER project\\\\Actor_*\\\\*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        if emotion not in observed_emotions:\n",
    "            continue\n",
    "        feature=extract_feature(file, mfcc=True, chroma=True, mel=True)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to split the dataset into training and testing sets! Let’s keep the test set 25% of everything and use the load_data function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "x_train,x_test,y_train,y_test=load_data(test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 192)\n"
     ]
    }
   ],
   "source": [
    "#Get the shape of the training and testing datasets\n",
    "print((x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features extracted: 180\n"
     ]
    }
   ],
   "source": [
    "#Get the number of features extracted\n",
    "print(f'Features extracted: {x_train.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08, \n",
    "                    hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.01, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              learning_rate='adaptive', max_iter=500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s predict the values for the test set. This gives us y_pred (the predicted emotions for the features in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict for the test set\n",
    "y_pred=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.52%\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy of our model\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "#Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Python mini project, we learned to recognize emotions from speech. We used an MLPClassifier for this and made use of the soundfile library to read the sound file, and the librosa library to extract features from it. As you’ll see, the model delivered an accuracy of 72.4%. That’s good enough for us yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
